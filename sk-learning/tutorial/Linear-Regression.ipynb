{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Linear Regression Example\n",
    "\n",
    "Those examples use the `diabetes` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data diabetes loading ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Data diabetes loading ...\")\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data\n",
    "diabetes_Y = diabetes.target\n",
    "total_size = len(diabetes_Y)\n",
    "train_size = int(0.7 * total_size)\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(diabetes_Y))\n",
    "train_x = diabetes_X[indices[:train_size]]\n",
    "train_y = diabetes_Y[indices[:train_size]]\n",
    "\n",
    "test_x = diabetes_X[indices[train_size:]]\n",
    "test_y = diabetes_Y[indices[train_size:]]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "MSE 2855.80\n",
      "Variance score: 0.57\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(train_x, train_y)\n",
    "pred_y = regr.predict(test_x)\n",
    "mse = np.mean( (pred_y - test_y) ** 2)\n",
    "score = regr.score(test_x, test_y)\n",
    "print(\"Linear regression\")\n",
    "print(\"MSE %.2f\" % mse)\n",
    "print(\"Variance score: %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression with ridge(L2) regularization\n",
      "MSE 2916.04\n",
      "Variance score: 0.56\n"
     ]
    }
   ],
   "source": [
    "ridge = linear_model.Ridge(alpha = .1)\n",
    "ridge.fit(train_x, train_y)\n",
    "pred_y = ridge.predict(test_x)\n",
    "mse = np.mean( (pred_y - test_y) ** 2)\n",
    "score = ridge.score(test_x, test_y)\n",
    "print(\"Linear regression with ridge(L2) regularization\")\n",
    "print(\"MSE %.2f\" % mse)\n",
    "print(\"Variance score: %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression with Lasso(L1) regularization\n",
      "MSE 2842.24\n",
      "Variance score: 0.57\n"
     ]
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha = .1)\n",
    "lasso.fit(train_x, train_y)\n",
    "pred_y = lasso.predict(test_x)\n",
    "mse = np.mean( (pred_y - test_y) ** 2)\n",
    "score = lasso.score(test_x, test_y)\n",
    "print(\"Linear regression with Lasso(L1) regularization\")\n",
    "print(\"MSE %.2f\" % mse)\n",
    "print(\"Variance score: %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression with elastic net regularization\n",
      "MSE 4696.62\n",
      "Variance score: 0.29\n"
     ]
    }
   ],
   "source": [
    "elasticNet = linear_model.ElasticNet(l1_ratio=0.9, alpha=.1)\n",
    "elasticNet.fit(train_x, train_y)\n",
    "pred_y = elasticNet.predict(test_x)\n",
    "mse = np.mean( (pred_y - test_y) ** 2)\n",
    "score = elasticNet.score(test_x, test_y)\n",
    "print(\"Linear regression with elastic net regularization\")\n",
    "print(\"MSE %.2f\" % mse)\n",
    "print(\"Variance score: %.2f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The advantages of LARS are:\n",
    "1. It is numerically efficient in contexts where p >> n (i.e., when the number of dimensions is significantly greater than the number of points)\n",
    "2. It is computationally just as fast as forward selection and has the same order of complexity as an ordinary least squares.\n",
    "3. It produces a full piecewise linear solution path, which is useful in cross-validation or similar attempts to tune the model.\n",
    "3. If two variables are almost equally correlated with the response, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.\n",
    "4. It is easily modified to produce solutions for other estimators, like the Lasso.\n",
    "\n",
    "## The disadvantages of the LARS method include:\n",
    "1. Because LARS is based upon an iterative refitting of the residuals, it would appear to be especially sensitive to the effects of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Angle Regression\n",
      "MSE 2855.80\n",
      "Variance score: 0.57\n"
     ]
    }
   ],
   "source": [
    "lars = linear_model.Lars()\n",
    "lars.fit(train_x, train_y)\n",
    "pred_y = lars.predict(test_x)\n",
    "mse = np.mean( (pred_y - test_y) ** 2)\n",
    "score = lars.score(test_x, test_y)\n",
    "print(\"Least Angle Regression\")\n",
    "print(\"MSE %.2f\" % mse)\n",
    "print(\"Variance score: %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso with least angle regression\n",
      "MSE 3863.93\n",
      "Variance score: 0.42\n"
     ]
    }
   ],
   "source": [
    "lasso_lars = linear_model.LassoLars()\n",
    "lasso_lars.fit(train_x, train_y)\n",
    "pred_y = lasso_lars.predict(test_x)\n",
    "mse = np.mean( (pred_y - test_y) ** 2)\n",
    "score = lasso_lars.score(test_x, test_y)\n",
    "print(\"Lasso with least angle regression\")\n",
    "print(\"MSE %.2f\" % mse)\n",
    "print(\"Variance score: %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Orthogonal Matching Pursuit (OMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The advantages of Bayesian Regression are:\n",
    "1. It adapts to the data at hand.\n",
    "2. It can be used to include regularization parameters in the estimation procedure.\n",
    "\n",
    "## The disadvantages of Bayesian regression include:\n",
    "1. Inference of the model can be time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian regression with ridge regularization\n",
      "MSE 2871.90\n",
      "Variance score: 0.57\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.BayesianRidge()\n",
    "model.fit(train_x, train_y)\n",
    "pred_y = model.predict(test_x)\n",
    "mse = np.mean( (pred_y - test_y) ** 2)\n",
    "score = model.score(test_x, test_y)\n",
    "print(\"Bayesian regression with ridge regularization\")\n",
    "print(\"MSE %.2f\" % mse)\n",
    "print(\"Variance score: %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
